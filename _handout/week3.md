---
title: "Week 3: Spoken Language Processing in a Visual Context"
# subtitle: ""
author: "Yiling Huo"
date: \today
bibliography: eye-tracking-method.bib
csl: elsevier-vancouver.csl
reference-section-title: "References"

header-includes: 
  - \usepackage{gb4e}

nocite: |
  @tanenhaus2007eye; @huettig2011using

# Pandoc md YAML
geometry: "left=2cm,right=2cm,top=2cm,bottom=2cm"

# cd github\eye-tracking-workshop-slides\_handout

# pandoc week3.md -o week3.pdf -d default.yml
---

Research on eye movements in reading has a history of more than a century. In contrast, eye movements have only started to become a popular measure in studies of spoken language processing within the last couple of decades. In these studies, participants' eye movements to a visual display are recorded as they follow instructions, listen to sentences, or generate utterances about the "visual world". The visual world paradigm allows researchers to study real-time language comprehension and production in natural tasks. 

# The visual world paradigm

In a typical visual world experiment, the participants hear an utterance while looking at an experimental display, while their eye movements are recorded for later analyses. 

## The visual display

Typically, the visual display includes the object(s) mentioned in the utterance as well as a few distractors. The visual display can take the form of a semi-realistic scene, an array of objects, or even printed words. The visual display is typically presented 1-2 seconds before the onset of the utterance (preview time) and stays in view until the offset of the auditory stimuli. In some versions of the visual world paradigm, the visual display can be presented first, and a spoken sentence follows while a blank screen is shown. Such a setup is useful in the studies of short-term memory in language comprehension. 

![Typical visual world displays. Extract from @huettig2011using. \label{vwe-display}](img\vwe-display.jpg){width=30%}

## The auditory stimuli

## The task

## The linking hypothesis

Data collected in a visual world experiment is essentially the gaze position at particular time points in each trial. How to link these position data with language processing? The assumption that provides the link between language processing and eye movements in the visual world is essentially that **the activation of a linguistic representation determines the probability that a participant will shift attention to the corresponding picture and thus make a saccadic eye movement to fixate it**. Therefore, when gaze positions are averaged across multiple trials, researchers can calculate the proportion/probability of looks to the target object, representing activation of the target word. 

![Proportion of looks to each object in the visual display when listening to instructions such as "Pick up the beaker". Extract from @allopenna1998tracking. \label{allopenna}](img\allopenna.png){width=45%}

## Production studies

In production studies, participants see sets of objects or cartoons of events or actions. No spoken input is presented, but instead the participants are asked to describe what they see. Researchers typically determine which objects are inspected, in which order they are inspected, and when they are inspected relative to the participants'speech output. This provides information about the ways speakers coordinate the generation of utterance plans with the overt articulation. 

# Comprehension

# Production